{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PUBG_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarmientoj24/EE298/blob/master/PUBG_FINAL_FeatEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAoURHkyb9FP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6114633-9936-4673-a953-9f3d82c2c374"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "!chmod 600 '/content/drive/My Drive/pubg/train/train_V2.csv'\n",
        "INPUT_DIR = '/content/drive/My Drive/pubg'\n",
        "\n",
        "# Specific imports\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48xFsqbbcWQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Functions\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    #start_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    return df\n",
        "\n",
        "def reload():\n",
        "  print(\"Building dataframe...\")\n",
        "  gc.collect()\n",
        "  df = reduce_mem_usage(pd.read_csv(INPUT_DIR + '/train/train_V2.csv')) # <=========== Just a function to reduce memory usage\n",
        "\n",
        "  # Only take the samples with matches that have more than 1 player \n",
        "  # there are matches with no players or just one player ( those samples could affect our model badly) \n",
        "  df = df[df['maxPlace'] > 1]\n",
        "  invalid_match_ids = df[df['winPlacePerc'].isna()]['matchId'].values\n",
        "  df = df[-df['matchId'].isin(invalid_match_ids)]\n",
        "  print(\"Done loading train to dataframe...\")\n",
        "  return df\n",
        "\n",
        "def train_test_split(df, test_size=0.1):\n",
        "  match_ids = df['matchId'].unique().tolist()\n",
        "  train_size = int(len(match_ids) * (1 - test_size))\n",
        "  train_match_ids = random.sample(match_ids, train_size)\n",
        "\n",
        "  train = df[df['matchId'].isin(train_match_ids)]\n",
        "  test = df[-df['matchId'].isin(train_match_ids)]\n",
        "\n",
        "  return train, test\n",
        "  \n",
        "# Split train to train and eval set\n",
        "def generate_train_test_set(df, split):\n",
        "  print(\"Generating train and test set...\")\n",
        "  df.drop(columns=['matchType'], inplace=True)\n",
        "  \n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  train, val = train_test_split(df, split)\n",
        "  \n",
        "  return train[cols_to_fit], val[cols_to_fit]\n",
        "\n",
        "def generate_train_set(df):\n",
        "  print(\"Generating train and test set...\")\n",
        "  df.drop(columns=['matchType'], inplace=True)\n",
        "  \n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  train = df\n",
        "  \n",
        "  return train[cols_to_fit]\n",
        "\n",
        "def load_test():\n",
        "  print(\"Building dataframe...\")\n",
        "  df = reduce_mem_usage(pd.read_csv(INPUT_DIR + '/test/test_V2.csv')) # <=========== Just a function to reduce memory usage\n",
        "\n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  print(\"Done loading train to dataframe...\")\n",
        "  return df[cols_to_fit]\n",
        "\n",
        "def transform_preds(df_test, pred):\n",
        "  for i in range(len(df_test)):\n",
        "      winPlacePerc_m = pred[i]\n",
        "      maxPlace = int(df_test.iloc[i]['maxPlace'])\n",
        "      if maxPlace == 0:\n",
        "          winPlacePerc_m = 0.0\n",
        "      elif maxPlace == 1:\n",
        "          winPlacePerc_m = 1.0\n",
        "      else:\n",
        "          gap = 1.0 / (maxPlace - 1)\n",
        "          winPlacePerc_m = np.round(winPlacePerc_m / gap) * gap\n",
        "\n",
        "      if winPlacePerc_m < 0: winPlacePerc_m = 0.0\n",
        "      if winPlacePerc_m > 1: winPlacePerc_m = 1.0    \n",
        "      pred[i] = winPlacePerc_m\n",
        "\n",
        "      if (i + 1) % 100000 == 0:\n",
        "          print(i, flush=True, end=\" \")\n",
        "\n",
        "  df_test['winPlacePerc_mod'] = pred\n",
        "  return df_test\n",
        "\n",
        "\n",
        "def run_experiment(preprocess):\n",
        "    df = reload()\n",
        "    df.drop(columns=['matchType'], inplace=True)\n",
        "    \n",
        "    df = preprocess(df)\n",
        "\n",
        "    score = run_lgb2(df)\n",
        "    return score\n",
        "\n",
        "def run_experiments(preprocesses):\n",
        "    results = []\n",
        "    for preprocess in preprocesses:\n",
        "        start = time.time()\n",
        "        score = run_experiment(preprocess)\n",
        "        execution_time = time.time() - start\n",
        "        results.append({\n",
        "            'name': preprocess.__name__,\n",
        "            'score': score,\n",
        "            'execution time': f'{round(execution_time, 2)}s'\n",
        "        })\n",
        "        gc.collect()\n",
        "        \n",
        "    return pd.DataFrame(results, columns=['name', 'score', 'execution time']).sort_values(by='score')\n",
        "\n",
        "\n",
        "def save_for_submission(df, path):\n",
        "  submission = df_test[['Id', 'winPlacePerc']]\n",
        "  submission.to_csv(path + 'submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jh80A3JcY9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Selectors\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Feature Selectors\n",
        "def run_lightgbmreg(df):\n",
        "  print(\"LightGBM: Start Light Gradient Boosted Regression...\")\n",
        "\n",
        "  target = 'winPlacePerc'\n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  train, val = train_test_split(df, 0.1)\n",
        "\n",
        "  params = {\n",
        "      'n_estimators': 100,\n",
        "      'learning_rate': 0.3, \n",
        "      'num_leaves': 20,\n",
        "      'objective': 'regression_l2', \n",
        "      'metric': 'mae',\n",
        "      'verbose': -1,\n",
        "  }\n",
        "\n",
        "  model = LGBMRegressor(**params)\n",
        "  model.fit(\n",
        "      train[cols_to_fit], train[target],\n",
        "      eval_metric='mae',\n",
        "      verbose=20,\n",
        "  )\n",
        "  \n",
        "  y_true = val[target]\n",
        "  y_pred = model.predict(val[cols_to_fit])\n",
        "  \n",
        "  print(\"LightGBM: Selecting features\")\n",
        "  feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_, cols_to_fit), reverse=True), columns=['Value','Feature'])\n",
        "  print(feature_importance)\n",
        "  \n",
        "  return mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "def run_lgb2(df):\n",
        "  print(\"LightGBM: Start Light Gradient Boosted Regression...\")\n",
        "\n",
        "  target = 'winPlacePerc'\n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  train, val = train_test_split(df, 0.1)\n",
        "\n",
        "  params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators': 50,\n",
        "              \"num_leaves\" : 20, \"learning_rate\" : 0.3, \"bagging_fraction\" : 0.7,\n",
        "               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n",
        "             }\n",
        "\n",
        "  model = LGBMRegressor(**params)\n",
        "  model.fit(\n",
        "      train[cols_to_fit], train[target],\n",
        "      eval_metric='mae',\n",
        "      verbose=20,\n",
        "  )\n",
        "  \n",
        "  y_true = val[target]\n",
        "  y_pred = model.predict(val[cols_to_fit])\n",
        "  \n",
        "  print(\"LightGBM: Selecting features\")\n",
        "  feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_, cols_to_fit), reverse=True), columns=['Value','Feature'])\n",
        "  print(feature_importance)\n",
        "  \n",
        "  return mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "def run_xgboost(df):\n",
        "  print(\"XGBoost: Start XGBoost Regression...\")\n",
        "\n",
        "  target = 'winPlacePerc'\n",
        "  cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n",
        "  cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n",
        "  train, val = train_test_split(df, 0.1)\n",
        "\n",
        "  params = {\n",
        "      'n_estimators': 40,\n",
        "      'learning_rate': 0.1, \n",
        "      'num_leaves': 20,\n",
        "      'objective': 'binary:logistic', \n",
        "      'metric': 'mae',\n",
        "      'verbose': 20,\n",
        "      'seed' : 42\n",
        "  }\n",
        "\n",
        "  model = XGBRegressor(**params)\n",
        "  model.fit(\n",
        "      train[cols_to_fit], train[target],\n",
        "      eval_set=[(val[cols_to_fit], val[target])],\n",
        "      eval_metric='mae',\n",
        "      verbose=20,\n",
        "  )\n",
        "  \n",
        "  print(\"XGBoost: Selecting features\")\n",
        "  feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_, cols_to_fit), reverse=True), columns=['Value','Feature'])\n",
        "  print(feature_importance)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxZNPlkwfSQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Engineering\n",
        "# Helper Functions\n",
        "\n",
        "def add_players_join(df):\n",
        "  df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n",
        "  return df\n",
        "\n",
        "def get_normalized_killsnorm_damagedealt(df):\n",
        "  if 'playersJoined' not in df.columns:\n",
        "    df = add_players_join(df)\n",
        "  df['killsNorm'] = df['kills']*((100-df['playersJoined'])/100 + 1)\n",
        "  df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])/100 + 1)\n",
        "  return df\n",
        "\n",
        "def add_heals_boosts(df):\n",
        "  df['healsAndBoosts'] = df['heals'] + df['boosts']\n",
        "  return df\n",
        "\n",
        "def get_total_distance_walked(df):\n",
        "  df['totalDistance'] = df['walkDistance']+ df['rideDistance']+ df['swimDistance']\n",
        "  return df\n",
        "\n",
        "def get_team_category(df):\n",
        "  df['team'] = [1 if i>50 else 2 if (i>25 & i<=50) else 4 for i in df['numGroups']]\n",
        "  return df\n",
        "\n",
        "def get_players_in_team(df):\n",
        "    agg = df.groupby(['groupId']).size().to_frame('players_in_team')\n",
        "    return df.merge(agg, how='left', on=['groupId'])\n",
        "\n",
        "def get_headshotKills_over_kills(df):\n",
        "  df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
        "  df['headshotKills_over_kills'].fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "def get_killPlace_over_maxPlace(df):\n",
        "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
        "    df['killPlace_over_maxPlace'].fillna(0, inplace=True)\n",
        "    df['killPlace_over_maxPlace'].replace(np.inf, 0, inplace=True)\n",
        "    return df\n",
        "\n",
        "def get_walk_distance_over_heals(df):\n",
        "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
        "    df['walkDistance_over_heals'].fillna(0, inplace=True)\n",
        "    df['walkDistance_over_heals'].replace(np.inf, 0, inplace=True)\n",
        "    return df\n",
        "  \n",
        "def get_walk_distance_over_boosts(df):\n",
        "    df['walkDistance_over_boosts'] = df['walkDistance'] / df['boosts']\n",
        "    df['walkDistance_over_boosts'].fillna(0, inplace=True)\n",
        "    df['walkDistance_over_boosts'].replace(np.inf, 0, inplace=True)\n",
        "    return df\n",
        "\n",
        "def get_walk_distance_over_kills(df):\n",
        "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
        "    df['walkDistance_over_kills'].fillna(0, inplace=True)\n",
        "    df['walkDistance_over_kills'].replace(np.inf, 0, inplace=True)\n",
        "    return df\n",
        "\n",
        "def get_teamwork(df):\n",
        "    df['teamwork'] = df['assists'] + df['revives']\n",
        "    return df\n",
        "\n",
        "# BY AGGREGATES, meaning, they calculate mean/max/min, etc of each columns then add it into the left of the existing one\n",
        "def add_min_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId','groupId'])[features].min()\n",
        "    return df.merge(agg, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "def add_max_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].max()\n",
        "    return df.merge(agg, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "def add_sum_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].sum()\n",
        "    return df.merge(agg, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "def add_median_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].median()\n",
        "    return df.merge(agg, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "def add_mean_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n",
        "    return df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "def add_rank_by_team(df):\n",
        "    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n",
        "    features = [col for col in df.columns if col not in cols_to_drop]\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n",
        "    agg = agg.groupby('matchId')[features].rank(pct=True)\n",
        "    return df.merge(agg, suffixes=['', '_mean_rank'], how='left', on=['matchId', 'groupId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f05U69yMsRIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature combos\n",
        "# Here, you could mix-in different features by just creating your own function\n",
        "# Your goal is to create a perfect mix of features here by\n",
        "# 1. Create own feature column (above)\n",
        "# 2. Test collection of features on a standard feature selection by run_experiments\n",
        "# 3. Investigate which feature groups have high results on #2\n",
        "# 4. Check among #3 which are great contributor features and select them\n",
        "# 5. Run #2 again using features obtained from #4\n",
        "# 6. Do until you get better results. \n",
        "def original(df):\n",
        "  return df\n",
        "  \n",
        "def put_everything_and_median(df):\n",
        "  df = add_players_join(df)\n",
        "  df = get_normalized_killsnorm_damagedealt(df)\n",
        "  df = add_heals_boosts(df)\n",
        "  df = get_total_distance_walked(df)\n",
        "  df = get_team_category(df)\n",
        "  df = get_players_in_team(df)\n",
        "  df = get_headshotKills_over_kills(df)\n",
        "  df = get_killPlace_over_maxPlace(df)\n",
        "  df = get_walk_distance_over_heals(df)\n",
        "  df = get_walk_distance_over_boosts(df)\n",
        "  df = get_walk_distance_over_kills(df)\n",
        "  df = get_teamwork(df)\n",
        "  df = add_median_by_team(df)\n",
        "  return df\n",
        "\n",
        "def just_median(df):\n",
        "  df = add_median_by_team(df)\n",
        "  return df\n",
        "\n",
        "def put_everything(df):\n",
        "  df = add_players_join(df)\n",
        "  df = get_normalized_killsnorm_damagedealt(df)\n",
        "  df = add_heals_boosts(df)\n",
        "  df = get_total_distance_walked(df)\n",
        "  df = get_team_category(df)\n",
        "  df = get_players_in_team(df)\n",
        "  df = get_headshotKills_over_kills(df)\n",
        "  df = get_killPlace_over_maxPlace(df)\n",
        "  df = get_walk_distance_over_heals(df)\n",
        "  df = get_walk_distance_over_boosts(df)\n",
        "  df = get_walk_distance_over_kills(df)\n",
        "  df = get_teamwork(df)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddoIrsI4uNsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1d620283-733c-410f-c99d-13b55de9df47"
      },
      "source": [
        "# Experiment Feature Selection Here\n",
        "experiment_scores = run_experiments([\n",
        "    original, # original dataframe\n",
        "    put_everything,\n",
        "    just_median,\n",
        "    put_everything_and_median\n",
        "])\n",
        "\n",
        "# Print Scores\n",
        "print(experiment_scores)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building dataframe...\n",
            "Done loading train to dataframe...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-13332dbfa872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mput_everything\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mjust_median\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mput_everything_and_median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f72405f7ad8b>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(preprocesses)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mexecution_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         results.append({\n",
            "\u001b[0;32m<ipython-input-14-f72405f7ad8b>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(preprocess)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_lgb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: run_lgb2() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d9YWdp3ulyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}