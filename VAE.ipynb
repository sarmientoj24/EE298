{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarmientoj24/EE298/blob/master/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wjy3eSsAgi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Lambda, Input, Dense, BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Activation\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as nps\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXjjzu61Cc9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reparameterization trick\n",
        "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
        "# z = z_mean + sqrt(var)*eps\n",
        "def sampling2(args):\n",
        "  z_mean, z_log_var = args\n",
        "  batch = K.shape(z_mean)[0]\n",
        "  dim = K.int_shape(z_mean)[1]\n",
        "  # by default, random_normal has mean=0 and std=1.0\n",
        "  epsilon = K.random_normal(shape=(batch, dim))\n",
        "  return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "# DISCRETE EPSILON for Code Generation\n",
        "# To Use:\n",
        "# Encoder's last layer should output z_mean, z_log_var, and possible z.\n",
        "# But on encoding dataset in Code Generation, we disregard z and use this function\n",
        "# to compute for a discrete z using z_mean and z_log_var\n",
        "def discrete_z_sampling(args):\n",
        "  z_mean, z_log_var, epsilon_discrete = args\n",
        "\n",
        "  return z_mean + K.exp(0.5 * z_log_var) * epsilon_discrete\n",
        "\n",
        "def randomly_sample_epsilon_discrete(dimension):\n",
        "  epsilon_discrete = K.random_normal(shape=(1, dimension))\n",
        "  print(\"Generating discrete epsilon...\")\n",
        "  print(epsilon_discrete)\n",
        "  return epsilon_discrete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HeC6igzCyz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we Plotter functions here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPN0BhEZC0IX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23e55b06-54cf-4fd7-9a5d-b3b1dd4ccf46"
      },
      "source": [
        "# Implement VAE here\n",
        "\n",
        "class VAE():\n",
        "  image_shape = (80, 60, 3)\n",
        "\n",
        "  def __init__(self):\n",
        "    # Build encoder\n",
        "    # Adopted from https://github.com/YongWookHa/VAE-Keras/blob/master/VAE.py\n",
        "\n",
        "    self.encoder_inputs = Input(shape=self.image_shape)\n",
        "    filter_dim = 128\n",
        "    z_dim = 10\n",
        "    x = self.encoder_inputs\n",
        "    x = Conv2D(int(filter_dim/16), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(int(filter_dim/8), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(int(filter_dim/4), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(int(filter_dim/2), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(filter_dim, kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    # x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    enc_shape = K.int_shape(x)\n",
        "    print(enc_shape)\n",
        "    # generate latent vector Q(z|X)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    z_mean = Dense(z_dim, name='z_mean')(x)\n",
        "    z_log_var = Dense(z_dim, name='z_log_var')(x)\n",
        "\n",
        "    # use reparameterization trick to push the sampling out as input\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    # instantiate encoder model\n",
        "    self.encoder = Model(self.encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "    self.encoder.summary()\n",
        "    plot_model(self.encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
        "\n",
        "    # Decoder\n",
        "    self.latent_inputs = Input(shape=(z_dim,), name='z_sampling')\n",
        "    z = Dense(enc_shape[1] * enc_shape[2] * enc_shape[3], activation='relu')(self.latent_inputs)\n",
        "    z = Reshape((enc_shape[1], enc_shape[2], enc_shape[3]))(z)\n",
        "    z = Conv2DTranspose(int(filter_dim/2), kernel_size=(2, 2), strides=2, padding='same')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('relu')(z)\n",
        "    z = Conv2DTranspose(int(filter_dim/4), kernel_size=(2,2), strides=2, padding='same')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('relu')(z)\n",
        "    z = Conv2DTranspose(int(filter_dim/8), kernel_size=(2,2), strides=2, padding='same')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('relu')(z)\n",
        "    z = Conv2DTranspose(int(filter_dim/16), kernel_size=(2,2), strides=2, padding='same')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('relu')(z)\n",
        "    z = Conv2DTranspose(3, kernel_size=(2,2), strides=(2,2), padding='same')(z)\n",
        "    encoder_output = Activation('tanh')(z)\n",
        "\n",
        "    # instantiate decoder model\n",
        "    self.decoder = Model(self.latent_inputs, encoder_output, name='decoder')\n",
        "    self.decoder.summary()\n",
        "    plot_model(self.decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
        "\n",
        "    # instantiate VAE model\n",
        "    outputs = self.decoder(self.encoder(self.encoder_inputs)[2])\n",
        "    vae = Model(self.encoder_inputs, outputs, name='vae')\n",
        "    vae.summary()\n",
        "\n",
        "  def save_encoder_to_h5(self):\n",
        "    pass\n",
        "  \n",
        "  def save_decoder_to_h5(self):\n",
        "    pass\n",
        "  \n",
        "  def save_vae_to_h5(self):\n",
        "    pass\n",
        "\n",
        "x = VAE()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 3, 2, 128)\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_46 (InputLayer)           (None, 80, 60, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 40, 30, 8)    104         input_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 40, 30, 8)    32          conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_238 (LeakyReLU)     (None, 40, 30, 8)    0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 20, 15, 16)   528         leaky_re_lu_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 20, 15, 16)   64          conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_239 (LeakyReLU)     (None, 20, 15, 16)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 10, 8, 32)    2080        leaky_re_lu_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 10, 8, 32)    128         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_240 (LeakyReLU)     (None, 10, 8, 32)    0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 5, 4, 64)     8256        leaky_re_lu_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 5, 4, 64)     256         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_241 (LeakyReLU)     (None, 5, 4, 64)     0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 3, 2, 128)    32896       leaky_re_lu_241[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 3, 2, 128)    512         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_242 (LeakyReLU)     (None, 3, 2, 128)    0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_47 (Flatten)            (None, 768)          0           leaky_re_lu_242[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_70 (Dense)                (None, 64)           49216       flatten_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_243 (LeakyReLU)     (None, 64)           0           dense_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 10)           650         leaky_re_lu_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 10)           650         leaky_re_lu_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 3)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 95,372\n",
            "Trainable params: 94,876\n",
            "Non-trainable params: 496\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 768)               8448      \n",
            "_________________________________________________________________\n",
            "reshape_31 (Reshape)         (None, 3, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_126 (Conv2D (None, 6, 4, 64)          32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_306 (Bat (None, 6, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_112 (Activation)  (None, 6, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_127 (Conv2D (None, 12, 8, 32)         8224      \n",
            "_________________________________________________________________\n",
            "batch_normalization_307 (Bat (None, 12, 8, 32)         128       \n",
            "_________________________________________________________________\n",
            "activation_113 (Activation)  (None, 12, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_128 (Conv2D (None, 24, 16, 16)        2064      \n",
            "_________________________________________________________________\n",
            "batch_normalization_308 (Bat (None, 24, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_114 (Activation)  (None, 24, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_129 (Conv2D (None, 48, 32, 8)         520       \n",
            "_________________________________________________________________\n",
            "batch_normalization_309 (Bat (None, 48, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_115 (Activation)  (None, 48, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_130 (Conv2D (None, 96, 64, 3)         99        \n",
            "_________________________________________________________________\n",
            "activation_116 (Activation)  (None, 96, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 52,667\n",
            "Trainable params: 52,427\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_46 (InputLayer)        (None, 80, 60, 3)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 10), (None, 10),  95372     \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 96, 64, 3)         52667     \n",
            "=================================================================\n",
            "Total params: 148,039\n",
            "Trainable params: 147,303\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ChmZS4OkGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c7f96b0-67c5-4374-d877-fde3a2784bb6"
      },
      "source": [
        ""
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 3, 2, 128)\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_40 (InputLayer)           (None, 80, 60, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 40, 30, 8)    104         input_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 40, 30, 8)    32          conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_202 (LeakyReLU)     (None, 40, 30, 8)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 20, 15, 16)   528         leaky_re_lu_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 20, 15, 16)   64          conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_203 (LeakyReLU)     (None, 20, 15, 16)   0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 10, 8, 32)    2080        leaky_re_lu_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 10, 8, 32)    128         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_204 (LeakyReLU)     (None, 10, 8, 32)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 5, 4, 64)     8256        leaky_re_lu_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 5, 4, 64)     256         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_205 (LeakyReLU)     (None, 5, 4, 64)     0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 3, 2, 128)    32896       leaky_re_lu_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 3, 2, 128)    512         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_206 (LeakyReLU)     (None, 3, 2, 128)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_41 (Flatten)            (None, 768)          0           leaky_re_lu_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 64)           49216       flatten_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_207 (LeakyReLU)     (None, 64)           0           dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 10)           650         leaky_re_lu_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 10)           650         leaky_re_lu_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 3)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 95,372\n",
            "Trainable params: 94,876\n",
            "Non-trainable params: 496\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 768)               8448      \n",
            "_________________________________________________________________\n",
            "reshape_25 (Reshape)         (None, 3, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_96 (Conv2DT (None, 6, 4, 64)          32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_252 (Bat (None, 6, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 6, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_97 (Conv2DT (None, 12, 8, 32)         8224      \n",
            "_________________________________________________________________\n",
            "batch_normalization_253 (Bat (None, 12, 8, 32)         128       \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 12, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_98 (Conv2DT (None, 24, 8, 16)         3088      \n",
            "_________________________________________________________________\n",
            "batch_normalization_254 (Bat (None, 24, 8, 16)         64        \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 24, 8, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_99 (Conv2DT (None, 48, 16, 8)         520       \n",
            "_________________________________________________________________\n",
            "batch_normalization_255 (Bat (None, 48, 16, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 48, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_100 (Conv2D (None, 48, 32, 3)         99        \n",
            "_________________________________________________________________\n",
            "activation_86 (Activation)   (None, 48, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 53,691\n",
            "Trainable params: 53,451\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_40 (InputLayer)        (None, 80, 60, 3)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 10), (None, 10),  95372     \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 48, 32, 3)         53691     \n",
            "=================================================================\n",
            "Total params: 149,063\n",
            "Trainable params: 148,327\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISCuJzjvPT-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}