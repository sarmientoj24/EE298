{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarmientoj24/EE298/blob/master/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wjy3eSsAgi_",
        "colab_type": "code",
        "outputId": "27dc66ad-0209-40dd-de46-55e22ce66281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "from keras.layers import Lambda, Input, Dense, BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Activation, Conv2D, Conv2DTranspose, Flatten, Dense, Reshape\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "\n",
        "import numpy as nps\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# Main cell to run\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXjjzu61Cc9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement VAE here\n",
        "\n",
        "class VAE():\n",
        "  image_shape = (80, 60, 3)\n",
        "\n",
        "  def __init__(self, load=False, encoder_h5=None, \n",
        "               decoder_h5=None):\n",
        "    # Build encoder\n",
        "    # Adopted from https://github.com/YongWookHa/VAE-Keras/blob/master/VAE.py\n",
        "\n",
        "    if load:\n",
        "      print(\"Loading model from h5...\")\n",
        "      self.load_model(encoder_h5, layer_ = 'encoder')\n",
        "      self.load_model(decoder_h5, layer_ = 'decoder')\n",
        "\n",
        "    else:\n",
        "      print(\"Creating model architecture...\")\n",
        "      # self.encoder_inputs = Input(shape=self.image_shape)\n",
        "      # filter_dim = 128\n",
        "      # x = self.encoder_inputs\n",
        "      # x = Conv2D(int(filter_dim/16), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # x = Conv2D(int(filter_dim/8), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # x = Conv2D(int(filter_dim/4), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # x = Conv2D(int(filter_dim/2), kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # x = Conv2D(filter_dim, kernel_size=(2,2), strides=(2,2), padding='SAME')(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # # x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "      # enc_shape = K.int_shape(x)\n",
        "      # print(enc_shape)\n",
        "      # # generate latent vector Q(z|X)\n",
        "      # x = Flatten()(x)\n",
        "      # x = Dense(64)(x)\n",
        "      # x = LeakyReLU(0.2)(x)\n",
        "      # z_mean = Dense(z_dim, name='z_mean')(x)\n",
        "      # z_log_sigma = Dense(z_dim, name='z_log_sigma')(x)\n",
        "\n",
        "      # # use reparameterization trick to push the sampling out as input\n",
        "      # # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "      # z = Lambda(self.sampling, output_shape=(z_dim,), name='z')([z_mean, z_log_sigma])\n",
        "\n",
        "      # # instantiate encoder model\n",
        "      # self.encoder = Model(self.encoder_inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "      # self.encoder.summary()\n",
        "      # plot_model(self.encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
        "\n",
        "      # # Decoder\n",
        "      # self.latent_inputs = Input(shape=(z_dim,), name='z_sampling')\n",
        "      # z = Dense(enc_shape[1] * enc_shape[2] * enc_shape[3], activation='relu')(self.latent_inputs)\n",
        "      # z = Reshape((enc_shape[1], enc_shape[2], enc_shape[3]))(z)\n",
        "      # z = Conv2DTranspose(int(filter_dim/2), kernel_size=(1, 2), strides=(2,1), padding='same')(z)\n",
        "      # z = BatchNormalization()(z)\n",
        "      # z = Activation('relu')(z)\n",
        "      # z = Conv2DTranspose(int(filter_dim/4), kernel_size=(2,2), strides=(2,2), padding='same')(z)\n",
        "      # z = BatchNormalization()(z)\n",
        "      # z = Activation('relu')(z)\n",
        "      # z = Conv2DTranspose(int(filter_dim/8), kernel_size=(2,1), strides=(2,2), padding='same')(z)\n",
        "      # z = BatchNormalization()(z)\n",
        "      # z = Activation('relu')(z)\n",
        "      # z = Conv2DTranspose(int(filter_dim/16), kernel_size=(2,2), strides=(2,2), padding='same')(z)\n",
        "      # z = BatchNormalization()(z)\n",
        "      # z = Activation('relu')(z)\n",
        "      # z = Conv2DTranspose(3, kernel_size=(2,2), strides=(2,2), padding='same')(z)\n",
        "      # decoder_output = Activation('tanh')(z)\n",
        "\n",
        "      # # instantiate decoder model\n",
        "      # self.decoder = Model(self.latent_inputs, decoder_output, name='decoder')\n",
        "      # self.decoder.summary()\n",
        "      # plot_model(self.decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
        "\n",
        "      # # instantiate VAE model\n",
        "      # outputs = self.decoder(self.encoder(self.encoder_inputs)[2])\n",
        "      # self.vae = Model(self.encoder_inputs, outputs, name='vae')\n",
        "      # self.vae.summary()\n",
        "\n",
        "      #### Meryl Version modified\n",
        "      z_dim = 10\n",
        "      kernel_size = 2\n",
        "      latent_dim = 10\n",
        "      filter_dims = [8, 16, 32]\n",
        "      filter_decoder = [32, 16, 8]\n",
        "      \n",
        "      self.inputs = Input(shape=self.image_shape, name='encoder_input')\n",
        "      x = self.inputs\n",
        "      for i in range(2):\n",
        "        filters = filter_dims[i]\n",
        "        x = Conv2D(filters=filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=2,\n",
        "                  padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "      # shape info needed to build decoder model\n",
        "      shape = K.int_shape(x)\n",
        "\n",
        "      # generate latent vector Q(z|X)\n",
        "      x = Flatten()(x)\n",
        "      x = Dense(64, activation='relu')(x)\n",
        "      z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "      z_log_sigma = Dense(latent_dim, name='z_log_sigma')(x)\n",
        "\n",
        "      # use reparameterization trick to push the sampling out as input\n",
        "      # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "      z = Lambda(self.sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_sigma])\n",
        "\n",
        "      # instantiate encoder model\n",
        "      self.encoder = Model(self.inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "      self.encoder.summary()\n",
        "      plot_model(self.encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
        "\n",
        "      # build decoder model\n",
        "      self.latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "      x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(self.latent_inputs)\n",
        "      x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "      for i in range(2):\n",
        "        filters = filter_decoder[i]\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=2,\n",
        "                            padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "      outputs = Conv2DTranspose(filters=3,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='tanh',      # Changed to tanh because data preparation was geared to be [-1, 1]\n",
        "                                padding='same',\n",
        "                                name='decoder_output')(x)\n",
        "\n",
        "      # instantiate decoder model\n",
        "      self.decoder = Model(self.latent_inputs, outputs, name='decoder')\n",
        "      self.decoder.summary()\n",
        "      plot_model(self.decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
        "\n",
        "      # instantiate VAE model\n",
        "      outputs = self.decoder(self.encoder(self.inputs)[2])\n",
        "      self.vae = Model(self.inputs, outputs, name='vae')\n",
        "      self.vae.summary()\n",
        "\n",
        "      # Construct the Loss function\n",
        "      # VAE loss = mse_loss or xent_loss + kl_loss\n",
        "\n",
        "      reconstruction_loss = mse(K.flatten(self.inputs), K.flatten(outputs))\n",
        "      # #reconstruction_loss = binary_crossentropy(K.flatten(self.encoder_inputs),\n",
        "      # #                                           K.flatten(outputs))\n",
        "\n",
        "      reconstruction_loss *= self.image_shape[0] * self.image_shape[1] * self.image_shape[2]\n",
        "      kl_loss = 1 + (z_log_sigma ** 2) - K.square(z_mean) - K.exp(z_log_sigma ** 2)\n",
        "      kl_loss = K.sum(kl_loss, axis=-1)\n",
        "      kl_loss *= -0.5\n",
        "      vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "      # recon = K.sum(K.binary_crossentropy(K.flatten(outputs), K.flatten(self.encoder_inputs)), axis=1)\n",
        "      # kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
        "      # vae_loss = recon + kl\n",
        "      self.vae.add_loss(vae_loss)\n",
        "      # self.vae.metrics_tensors.append(reconstruction_loss)\n",
        "      # self.vae.metrics_names.append(\"val_loss\")\n",
        "      self.vae.compile(optimizer='adam')\n",
        "\n",
        "  def get_summary(layer_='vae'):\n",
        "    if layer_ == 'vae':\n",
        "      self.vae.summary()\n",
        "\n",
        "    elif layer == 'decoder':\n",
        "      self.decoder.summary()\n",
        "\n",
        "    else:\n",
        "      self.encoder.summary()\n",
        "  \n",
        "  def load_model(self, h5_file, layer_):\n",
        "    print(\"Loading h5 \", layer_)\n",
        "    if layer_ == 'encoder':\n",
        "      self.encoder = load_model(h5_file)\n",
        "    else:\n",
        "      self.decoder = load_model(h5_file)\n",
        "\n",
        "  def _fit(self, epochs, batch_size, x_train):\n",
        "    self.history = self.vae.fit(x_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=1)\n",
        "    self.vae.save('vae_mnist.h5')\n",
        "    self.encoder.save('vae_encoder.h5')\n",
        "    self.decoder.save('vae_decoder.h5')\n",
        "\n",
        "  def get_history(self):\n",
        "    return self.history\n",
        "  \n",
        "  def plot_loss_function(self):\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(self.history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "  def get_encoder_model(self):\n",
        "    return self.encoder\n",
        "  \n",
        "  def get_decoder_model(self):\n",
        "    return self.decoder\n",
        "  \n",
        "  def get_vae_model(self):\n",
        "    return self.vae\n",
        "  \n",
        "  # Sampling to be used in training\n",
        "  def sampling(self, args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(z_log_sigma / 2) * epsilon\n",
        "    # return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HeC6igzCyz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ImageEncoder\n",
        "# After training VAE, create a new model based of the trained encoder\n",
        "# for encoding the image samples\n",
        "class ImageEncoder():\n",
        "  input_shape = (80, 60, 3)\n",
        "\n",
        "  def __init__(self, encoder, z_dim=10):\n",
        "    self.encoder = Model(\n",
        "        Input(shape=input_shape),\n",
        "        encoder)\n",
        "    self.epsilon = K.random_normal(shape=(z_dim, ))\n",
        "  \n",
        "  def _encode_sampled(self, input_image):\n",
        "    z_mean, z_log_sigma, z = self.encoder.predict(input_image)\n",
        "    # We only need z_mean and z_log_sigma\n",
        "    return z_mean + K.exp(z_log_sigma / 2) * epsilon\n",
        "    # return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "  \n",
        "  def _encode(self, input_image):\n",
        "    z_mean, z_log_sigma, z = self.encoder.predict(input_image)\n",
        "    return z_mean, z_log_sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPN0BhEZC0IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### HELPER FUNCTIONS\n",
        "import cv2\n",
        "import glob, os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import imageio\n",
        "def read_imgs_to_np_from_folder(img_folder):\n",
        "  cwd = os.getcwd()\n",
        "\n",
        "  # os.chdir(img_folder + '/')\n",
        "\n",
        "  imgs = glob.glob(img_folder + '*.jpg')\n",
        "  # height,width = imageio.imread(imgs[0]).shape[:2]\n",
        "\n",
        "  X = []\n",
        "  count = 0\n",
        "  for f in imgs:\n",
        "    x = imageio.imread(f)\n",
        "\n",
        "    if len(x.shape) == 3 and x.shape[0] == 80 and x.shape[1] == 60 and x.shape[2] == 3:\n",
        "      x = x.astype(np.float32) / 255.0\n",
        "      X.append(x)\n",
        "      count += 1\n",
        "    if count % 10000 == 0:\n",
        "      print(\"Traversed \", count)\n",
        "    \n",
        "  X = np.array(X)\n",
        "  print(X.shape)\n",
        "  return X\n",
        "\n",
        "##### This function should be in the web-app (REMOVE once completed) ###########\n",
        "import math\n",
        "import numpy as np\n",
        "import operator\n",
        "# import pandas as pd\n",
        "\n",
        "# decoder_loaded_model = load_model('decoder.h5')\n",
        "\n",
        "def compute_log_likelihood(z_gen, mu_, log_sigma):\n",
        "  # (zi−μi(x))22σi(x)2\n",
        "  # Adopted here https://datascience.stackexchange.com/questions/64097/how-to-use-variational-autoencoders-%CE%BC-and-%CF%83-with-user-generated-z/64163#64163\n",
        "  term_a = (z_gen - mu_) ** 2\n",
        "  term_b = 2 * (log_sigma ** 2)\n",
        "  term_c = -1 * (term_a / term_b)\n",
        "\n",
        "  # −log(2π−−√σi(x))\n",
        "  term_d = np.log(((2 * np.pi) ** 0.5) * (log_sigma))\n",
        "  term_e = term_c - term_d\n",
        "\n",
        "  likelihood = np.sum(term_e)\n",
        "  return likelihood\n",
        "\n",
        "def find_nearest(z_var_generated):\n",
        "  # SQL Query get all of those needed and store to dataframe\n",
        "  # Do Query here\n",
        "  z_dim = len(z_var_generated)\n",
        "  z_var_generated = np.array(z_var_generated) # Convert to numpy\n",
        "\n",
        "  ids_ = sql_df['id'].to_list()\n",
        "  df = sql_df[['mu_1', 'mu_2', 'mu_3', 'mu_4', 'mu_5', \n",
        "               'mu_6', 'mu_7', 'mu_8', 'mu_9', 'mu_10',\n",
        "               'log_sigma_1', 'log_sigma_2', 'log_sigma_3', 'log_sigma_4', 'log_sigma_5',\n",
        "               'log_sigma_6', 'log_sigma_7', 'log_sigma_8', 'log_sigma_9', 'log_sigma_10']]\n",
        "  \n",
        "  datapoints_encoded_in_db = df.to_numpy()\n",
        "  rows = datapoints_encoded_in_db.shape[1]\n",
        "\n",
        "  likelihoods = {}\n",
        "\n",
        "  counter = 0\n",
        "  for data in rows:\n",
        "    mu_vector = data[:z_dim]\n",
        "    sigma_vector = data[z_dim:z_dim*2]\n",
        "    log_likelihood = compute_log_likelihood(z_var_generated,\n",
        "                                            mu_vector, log_sigma_vector)\n",
        "    likelihoods[id_s[counter]] = log_likelihood\n",
        "    counter += 1\n",
        "\n",
        "  # Sort dictionary by likelihood\n",
        "  sorted_x = sorted(likelihoods.items(), key=operator.itemgetter(1))\n",
        "\n",
        "  # return top three descending\n",
        "  return sorted_x[0], sorted_x[1], sorted_x[2]\n",
        "\n",
        "def decode_img(z_var_generated):\n",
        "  img = decoder_loaded_model.predict(z_var_generated)\n",
        "  return img\n",
        "\n",
        "##########Functions above are to be used inside the web-app locally hosted #########3\n",
        "\n",
        "# Function to use ENCODER and ENCODE datapoints to database\n",
        "# Could be run on Colab or PC with GPU/Keras\n",
        "import sqlite3\n",
        "def encode_img_from_folder_to_db(folder, db, encoder):\n",
        "  try:\n",
        "    conn = sqlite3.connect(db)\n",
        "  except Error as e:\n",
        "    print(e)\n",
        "\n",
        "  conn = self.create_connection(database)\n",
        "\n",
        "  sql = '''\n",
        "          SELECT id, image_id\n",
        "          FROM appchemy_apparel_dummy\n",
        "        '''\n",
        "\n",
        "  products_df = pd.read_sql_query(sql, conn)\n",
        "  image_ids = products_df['image_id'].to_list()\n",
        "\n",
        "  cwd = os.getcwd()\n",
        "  img_folder = folder + '/'\n",
        "\n",
        "  cur = conn.cursor()\n",
        "  os.chdir(img_folder)\n",
        "\n",
        "  for index, image_id in enumerate(image_ids):\n",
        "    img_name = str(image_id) + '.jpg'\n",
        "    \n",
        "    try:\n",
        "        img = cv2.imread(img_name, mode='RGB')\n",
        "        if img.shape() == (80, 60, 3):\n",
        "          mu_, log_sigma_ = encoder.__encode(img)      # change if either to store z or mu and log_var\n",
        "\n",
        "          # Update in db\n",
        "          sql = '''\n",
        "                UPDATE appchemy_apparel_dummy SET\n",
        "                mu_1 = {}, mu_2 = {}, mu_3 = {}, mu_4 = {}, mu_5 = {}, \n",
        "                mu_6 = {}, mu_7 = {}, mu_8 = {}, mu_9 = {}, mu_10 = {},\n",
        "                log_sigma_1 = {}, log_sigma_2 = {}, log_sigma_3 = {}, \n",
        "                log_sigma_4 = {}, log_sigma_5 = {}, log_sigma_6 = {}, \n",
        "                log_sigma_7 = {}, log_sigma_8 = {}, log_sigma_9 = {}, log_sigma_10 = {}\n",
        "                WHERE id = {}\n",
        "              '''.format(mu_[0], mu_[1], mu_[2], mu_[3], mu_[4], mu_[5], \n",
        "                         mu_[6], mu_[7], mu_[8], mu_[9], \n",
        "                         log_sigma_[0], log_sigma_[1], log_sigma_[2], log_sigma_[3], log_sigma_[4], \n",
        "                         log_sigma_[5], log_sigma_[6], log_sigma_[7], log_sigma_[8], log_sigma_[9],\n",
        "                         image_id)\n",
        "          cur.execute(sql)\n",
        "          if index % 200 == 0:\n",
        "            conn.commit()\n",
        "          print(\"File not 80x60x3: \", img_name)\n",
        "    except:\n",
        "      print(\"Error reading file: \", img_name)\n",
        "      continue\n",
        "\n",
        "  conn.commit()\n",
        "  conn.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ChmZS4OkGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !chmod 600 '/content/drive/My Drive/ee298/dataset.tar.xz'\n",
        "# !cp '/content/drive/My Drive/ee298/dataset.tar.xz' '/content/data_im/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISCuJzjvPT-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -xf '/content/data_im/dataset.tar.xz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kct5vlU4iuY1",
        "colab_type": "code",
        "outputId": "21c405c9-a967-44e6-dee3-ff57f6955548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "x_train = read_imgs_to_np_from_folder('/content/apparel_reduced/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traversed  10000\n",
            "Traversed  20000\n",
            "Traversed  30000\n",
            "Traversed  40000\n",
            "Traversed  50000\n",
            "Traversed  60000\n",
            "Traversed  70000\n",
            "Traversed  80000\n",
            "Traversed  90000\n",
            "(92013, 80, 60, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgYvZ3WOrMmp",
        "colab_type": "code",
        "outputId": "96698924-f06b-4571-d50e-5796dd3d4484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# vae_x = VAE()\n",
        "\n",
        "# vae_x._fit(\n",
        "#     epochs=5,\n",
        "#     batch_size=32,\n",
        "#     x_train=x_train\n",
        "# )\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(z_log_sigma / 2) * epsilon\n",
        "\n",
        "z_dim = 10\n",
        "kernel_size = 2\n",
        "latent_dim = 10\n",
        "filter_dims = [8, 16, 32]\n",
        "filter_decoder = [32, 16, 8]\n",
        "image_shape = (80, 60, 3)\n",
        "epochs = 20\n",
        "batch_size=32\n",
        "from keras import layers, initializers\n",
        "\n",
        "inputs = Input(shape=image_shape, name='encoder_input')\n",
        "x = inputs\n",
        "for i in range(2):\n",
        "  filters = filter_dims[i]\n",
        "  x = Conv2D(filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=2,\n",
        "            padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)\n",
        "\n",
        "# shape info needed to build decoder model\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "# generate latent vector Q(z|X)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_sigma = Dense(latent_dim, name='z_log_sigma',\n",
        "      kernel_initializer='random_uniform',\n",
        "      bias_initializer=initializers.Constant(0.1))(x)\n",
        "\n",
        "# use reparameterization trick to push the sampling out as input\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_sigma])\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "encoder.summary()\n",
        "plot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
        "\n",
        "# build decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for i in range(2):\n",
        "  filters = filter_decoder[i]\n",
        "  x = Conv2DTranspose(filters=filters,\n",
        "                      kernel_size=kernel_size,\n",
        "                      strides=2,\n",
        "                      padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "outputs = Conv2DTranspose(filters=3,\n",
        "                          kernel_size=kernel_size,\n",
        "                          activation='sigmoid',\n",
        "                          padding='same',\n",
        "                          name='decoder_output')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "plot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae')\n",
        "vae.summary()\n",
        "\n",
        "# Construct the Loss function\n",
        "# VAE loss = mse_loss or xent_loss + kl_loss\n",
        "\n",
        "# reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
        "reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n",
        "                                           K.flatten(outputs))\n",
        "\n",
        "reconstruction_loss *= image_shape[0] * image_shape[1] * image_shape[2]\n",
        "kl_loss = 1 + (z_log_sigma ** 2) - K.square(z_mean) - K.exp(z_log_sigma ** 2)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# recon = K.sum(K.binary_crossentropy(K.flatten(inputs), K.flatten(outputs)))\n",
        "# kl = 0.5 * K.sum(K.exp(z_log_sigma) + K.square(z_mean) - 1. - z_log_sigma, axis=1)\n",
        "# vae_loss = recon + kl\n",
        "\n",
        "# vae.metrics_tensors.append(reconstruction_loss)\n",
        "# vae.metrics_names.append(\"val_loss\")\n",
        "\n",
        "# translate our loss into Keras code\n",
        "# def vae_loss(y_true, y_pred):\n",
        "#     \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
        "#     recon = K.sum(K.binary_crossentropy(y_true, y_pred))\n",
        "#     kl = 0.5 * K.sum(K.exp(z_log_sigma) + K.square(z_mean) - 1. - z_log_sigma, axis=1)\n",
        "#     return recon + kl\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "history = vae.fit(x_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=1)\n",
        "vae.save('vae_mnist.h5')\n",
        "encoder.save('vae_encoder.h5')\n",
        "decoder.save('vae_decoder.h5')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, 80, 60, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 30, 8)    104         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 40, 30, 8)    32          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 40, 30, 8)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 15, 16)   528         leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 20, 15, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 20, 15, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4800)         0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           307264      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 10)           650         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_sigma (Dense)             (None, 10)           650         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 10)           0           z_mean[0][0]                     \n",
            "                                                                 z_log_sigma[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 309,292\n",
            "Trainable params: 309,244\n",
            "Non-trainable params: 48\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4800)              52800     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 20, 15, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 40, 30, 32)        2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 40, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 40, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 80, 60, 16)        2064      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 80, 60, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 80, 60, 16)        0         \n",
            "_________________________________________________________________\n",
            "decoder_output (Conv2DTransp (None, 80, 60, 3)         195       \n",
            "=================================================================\n",
            "Total params: 57,331\n",
            "Trainable params: 57,235\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 80, 60, 3)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 10), (None, 10),  309292    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 80, 60, 3)         57331     \n",
            "=================================================================\n",
            "Total params: 366,623\n",
            "Trainable params: 366,479\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "92013/92013 [==============================] - 68s 740us/step - loss: 3135.4096\n",
            "Epoch 2/20\n",
            "92013/92013 [==============================] - 62s 677us/step - loss: 2917.2541\n",
            "Epoch 3/20\n",
            "92013/92013 [==============================] - 62s 679us/step - loss: 2895.7101\n",
            "Epoch 4/20\n",
            "92013/92013 [==============================] - 63s 680us/step - loss: 2884.5118\n",
            "Epoch 5/20\n",
            "92013/92013 [==============================] - 62s 679us/step - loss: 2877.1061\n",
            "Epoch 6/20\n",
            "92013/92013 [==============================] - 63s 686us/step - loss: 2871.3173\n",
            "Epoch 7/20\n",
            "92013/92013 [==============================] - 63s 680us/step - loss: 2866.4020\n",
            "Epoch 8/20\n",
            "92013/92013 [==============================] - 63s 682us/step - loss: 2863.3135\n",
            "Epoch 9/20\n",
            "92013/92013 [==============================] - 63s 682us/step - loss: 2859.8996\n",
            "Epoch 10/20\n",
            "92013/92013 [==============================] - 63s 681us/step - loss: 2857.0735\n",
            "Epoch 11/20\n",
            "92013/92013 [==============================] - 63s 684us/step - loss: 2854.9472\n",
            "Epoch 12/20\n",
            "92013/92013 [==============================] - 63s 682us/step - loss: 2852.9900\n",
            "Epoch 13/20\n",
            "92013/92013 [==============================] - 63s 680us/step - loss: 2851.3720\n",
            "Epoch 14/20\n",
            "92013/92013 [==============================] - 63s 679us/step - loss: 2849.4384\n",
            "Epoch 15/20\n",
            "92013/92013 [==============================] - 62s 678us/step - loss: 2848.0010\n",
            "Epoch 16/20\n",
            "92013/92013 [==============================] - 63s 683us/step - loss: 2846.6841\n",
            "Epoch 17/20\n",
            "92013/92013 [==============================] - 63s 683us/step - loss: 2845.5866\n",
            "Epoch 18/20\n",
            "92013/92013 [==============================] - 63s 683us/step - loss: 2843.8743\n",
            "Epoch 19/20\n",
            "92013/92013 [==============================] - 63s 680us/step - loss: 2843.4012\n",
            "Epoch 20/20\n",
            "92013/92013 [==============================] - 63s 680us/step - loss: 2842.2276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMijsP_Lxzgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28e20875-6eb2-4da0-93e2-ddaff2fd5913"
      },
      "source": [
        "imgs = glob.glob('/content/apparel_reduced/' + '*.jpg')\n",
        "img_1 = imgs[0]\n",
        "x = imageio.imread(img_1)\n",
        "x = x.astype(np.float32) / 255.0\n",
        "x = np.reshape(x, [-1, 80, 60, 3])\n",
        "print(x[0].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 60, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYxC1HLZv7mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_vae = vae.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqL2fXG1wG12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "969c03c6-3bc5-4eaf-84b8-a244c77a83e2"
      },
      "source": [
        "plt.imshow(out_vae[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f691c566208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAD7CAYAAADaSFAtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOJdoUuvwplO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6933750e-622d-404b-8cf6-c01afa6cb919"
      },
      "source": [
        "z_fake = np.random.normal(size=(10,))\n",
        "print(z_fake.shape)\n",
        "print(z_fake.reshape(-1, 10))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "[[-0.43117335  0.14660936  0.25846719 -0.07371592 -0.09508941 -0.33461092\n",
            "  -1.12508493 -0.1195196  -1.51547107 -0.12977388]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jOhk274yYwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_predicted = decoder.predict(z_fake.reshape(-1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp1oyl6jyl_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "7af03418-3ce1-4ae2-8aa8-1f3cd72e61dd"
      },
      "source": [
        "plt.imshow(fake_predicted[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f691a70a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAD7CAYAAADaSFAtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2UQvXm_zFsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}